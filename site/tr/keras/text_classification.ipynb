{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ic4_occAAiAT"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "ioaprt5q5US7"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "yCl0eTNH5RS3"
      },
      "outputs": [],
      "source": [
        "#@title MIT License\n",
        "#\n",
        "# Copyright (c) 2017 Fran√ßois Chollet\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ItXfxkxvosLH"
      },
      "source": [
        "# Onceden islenmis metin ile metin siniflandirilmasi: Film yorumlari"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hKY4XMc9o8iB"
      },
      "source": [
        "\u003ctable class=\"tfo-notebook-buttons\" align=\"left\"\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/keras/text_classification\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" /\u003eView on TensorFlow.org\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /\u003eRun in Google Colab\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /\u003eView source on GitHub\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/keras/text_classification.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/download_logo_32px.png\" /\u003eDownload notebook\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "\u003c/table\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Eg62Pmz3o83v"
      },
      "source": [
        "\n",
        "Bu kitapcikta film yorumlarini metinlerin icerigini kullanarak *olumlu* ve *olumsuz* olarak siniflandiracagiz. Bu onemli ve yogun olarak kullanilan *ikili*- ya da iki-yonlu-siniflandirma makine ogrenmesi sorununun bir ornegidir. \n",
        "\n",
        "[Internet Movie Database](https://www.imdb.com/) sitesinden alinan 50,000 film yorumu metnini barindiran [IMDB veri setini](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb) kullanacagiz. Bunlarin 25,000 adetini egitim icin kalan 25,000 adeti ise test icin ayiralim. Test ve egitim setleri *dengelidir*, yani esit sayida pozitif ve negatif yorum bulundururlar.\n",
        "\n",
        "Bu kitapcik yuksek-seviye API [tf.keras](https://www.tensorflow.org/guide/keras) kullanarak TensorFlow icinde modeli olusturur ve egitir. `tf.keras` kullanan daha ileri seviyede metin siniflandirmasi rehberi icin [buraya bakiniz](https://developers.google.com/machine-learning/guides/text-classification/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2ew7HTbPpCJH"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version sadece Colab icinde bulunur.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iAsKG535pHep"
      },
      "source": [
        "## IMDB veri setini indirelim\n",
        "\n",
        "IMDB veri seti TensorFlow paketi ile beraber gelir. Metinler (kelime siralari) hali hazirda sayi dizilerine cevrilmistir ki bu sayilar sozlukteki belirli kelimeleri temsil ederler.\n",
        "\n",
        "Asagidaki kod IMDB veri setini bilgisayariniza indirir (ya da daha once indirilmis ise onbellekteki kopyayi kullanir):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zXXx5Oc3pOmN"
      },
      "outputs": [],
      "source": [
        "imdb = keras.datasets.imdb\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "odr-KlzO-lkL"
      },
      "source": [
        "Bagimsiz degisken `num_words=10000` en cok gorulen ilk 10,000 kelimeyi egitim setinde tutar. Nadir gorulen kelimeler ise veri boyutunu kontrol altinda tutmak icin veri setinden atilir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l50X3GfjpU4r"
      },
      "source": [
        "## Veriyi inceleyelim\n",
        "\n",
        "Simdi biraz zaman ayirip verinin yapisini anlayalim. Veri seti onceden islenmistir: her ornek film yorumlarindaki kelimeleri temsil eden bir sayi dizisidir. Her etiket degeri 0 ya da 1 olan bir sayidir. 0 olumsuz yorum anlamina gelirken 1 olumlu yorumlardir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "y8qCnve_-lkO"
      },
      "outputs": [],
      "source": [
        "print(\"Training entries: {}, labels: {}\".format(len(train_data), len(train_labels)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RnKvHWW4-lkW"
      },
      "source": [
        "Yorum metinleri her sayinin sozlukteki belirli kelimeyi temsil ettigi sayi dizilerine cevrilmistir. Ilk yorumun nasil gozuktugune bir bakalim:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QtTS4kpEpjbi"
      },
      "outputs": [],
      "source": [
        "print(train_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hIE4l_72x7DP"
      },
      "source": [
        "Film yorumlari farkli uzunlukta olabilir. Asagidaki kod ilk ve ikinci yorumlardaki kelime sayisini gosterir. Sinir aglarina girislerin ayni uzunlukta olmasi gerekir, bu daha sonra ustunden gececegimiz bir konu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "X-6Ii9Pfx6Nr"
      },
      "outputs": [],
      "source": [
        "len(train_data[0]), len(train_data[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4wJg2FiYpuoX"
      },
      "source": [
        "### Sayilari kelimere geri cevirelim\n",
        "\n",
        "Sayilarin kelimelere cevrilip metni yeniden olusturmayi bilmek faydali olabilir. Burada yardimci bir fonksiyon ile sayi-kelime eslemelerini bulunduran sozluk nesnesini sorgulamasini yapacagiz:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tr5s_1alpzop"
      },
      "outputs": [],
      "source": [
        "# Kelimeleri sayilara eslestiren bir sozluk\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# The first indices are reserved\n",
        "word_index = {k:(v+3) for k,v in word_index.items()}\n",
        "word_index[\"\u003cPAD\u003e\"] = 0\n",
        "word_index[\"\u003cSTART\u003e\"] = 1\n",
        "word_index[\"\u003cUNK\u003e\"] = 2  # unknown\n",
        "word_index[\"\u003cUNUSED\u003e\"] = 3\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U3CNRvEZVppl"
      },
      "source": [
        "Simdi `decode_review` fonksiyonunu kullanarak ilk yorumun metnini gorebiliriz:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "s_OqxmH6-lkn"
      },
      "outputs": [],
      "source": [
        "decode_review(train_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lFP_XKVRp4_S"
      },
      "source": [
        "## Veriyi hazirlayalim\n",
        "\n",
        "Yorumlarin -sayi dizilerinin- sinir agina verilmeden once tensorlara donusturulmesi gerekmektedir. Bu donusum birkac yolla yapilabilir:\n",
        "\n",
        "* 'One-hot encoding' yonteminde oldugu gibi dizileri kelimelerin olusuna gore 0 ve 1'den olusan yoneylere cevirebiliriz. Ornegin, [3, 5] dizisi sadece 3 ve 5 dizininde 1 olan ve geri kalan elemanlari 0'dan olusan 10,000-boyutlu bir yoneye donusecektir. Sonra, bu yoney agimizin reel sayi yoney verisini idare edebilen ilk katmanini -yogun katmani- olusturur. Fakat, bu yontem 'num_words * num_reviews' boyutunda matris kadar hafizaya ihtiyac duyar.\n",
        "\n",
        "* Kullanabilecegimiz diger bir yontem ise dizileri doldurarak ayni uzunluga getirmektir. Sonra, `max_length * num_reviews` seklinde tensorlari olusturabiliriz. Olusan bu sekli idare edebilen gomulu katmani agimizin ilk katmani olarak kullanabiliriz.\n",
        "\n",
        "Bu egitimde ikinci yontemi kullanacagiz.\n",
        "\n",
        "Film yorumlarinin ayni uzunlukta olmasi gerektiginden [pad_sequences](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences) fonksiyonunu kullanarak uzunluklari standartlastiracagiz:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2jQv-omsHurp"
      },
      "outputs": [],
      "source": [
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
        "                                                        value=word_index[\"\u003cPAD\u003e\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=256)\n",
        "\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                       value=word_index[\"\u003cPAD\u003e\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VO5MBpyQdipD"
      },
      "source": [
        "Simdi orneklerimizin uzunluklarina bakalim:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "USSSBnkE-lky"
      },
      "outputs": [],
      "source": [
        "len(train_data[0]), len(train_data[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QJoxZGyfjT5V"
      },
      "source": [
        "Ve (simdi doldurulmus) ilk yorumu inceleyelim:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "TG8X9cqi-lk9"
      },
      "outputs": [],
      "source": [
        "print(train_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LLC02j2g-llC"
      },
      "source": [
        "## Modeli olusturalim\n",
        "\n",
        "Sinir agi katmanlarin ust uste eklenmesi ile olusturulur-bunun icin iki temel mimari karar gerekir:\n",
        "\n",
        "* Modelimizde kac adet katman kullanacagiz?\n",
        "* Her katmanda kac adet *gizli unite* bulunacak?\n",
        "\n",
        "Bu ornekte girdi verisi kelime dizinleri dizisinden olusmaktadir. Etiketlerin 0 ya da 1 tahmin etmesi gerekir. Bu problem icin modelimizi olusturalim:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xpKOoWgu-llD"
      },
      "outputs": [],
      "source": [
        "# Girdi sekli film yorumlarinda kullanilan kelime sayisidir (10,000 kelime)\n",
        "vocab_size = 10000\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size, 16))\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(16, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6PbKQ6mucuKL"
      },
      "source": [
        "Katmanlar sira ile birbirine eklenerek siniflandiriciyi olusturur:\n",
        "\n",
        "1. Ilk katman `gomulu` katmandir. Bu katman sayi-kodlu kelime hazinesini alir ve her kelime-dizini icin gomulu yoneye bakar. Bu yoneyler model treni olarak ogrenilir. Yoneyler cikti dizisine bir boyut eklerler. Elde edilen boyutlar: `(toplu, sira, gomulu)`.\n",
        "2. Sonra, `GlobalAveragePooling1D` katmani sira boyutunda ortalanan her ornek icin sabit-uzunlukta cikti yoneyleri dondurur. Bu modelin degisik uzunluktaki girdileri en basit sekilde halletmesini saglar.\n",
        "3. Bu sabit-uzunluktaki cikti yoneyi 16 gizli uniteden olusan tamamen-bagli (`Dense`) katmana gonderilir.\n",
        "4. Son katman tek cikti dugumlu yogun bagli bir katmandir. `Sigmoid` aktiflestirici fonksiyonunu kullanarak elde edilen bu deger, olasiligi ya da guven seviyesini temsil eden 0 ile 1 arasinda bir reel sayidir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0XMwnDOp-llH"
      },
      "source": [
        "### Gizli uniteler\n",
        "\n",
        "Yukaridaki model girdi ve cikti arasinda iki ara ya da \"gizli\" katman bulundurmaktadir. Cikti miktari (uniteler, dugumler ya da sinirler) katmani temsil eden boyuttur. Yani icsel temsil edilmeyi ogrenirken sinir aginin sahip oldugu ozgurluktur.\n",
        "\n",
        "Eger bir model daha cok gizli uniteye (yani daha cok boyutlu temsilsel alani) ve/veya katmani varsa, bu sinir agi daha karisik temsillemeler ogrenebilir. Fakat, bu agin daha cok kaynak kullanmasina neden olur ve istenmeyen kaliplarin ogrenilmesine neden olur. Bu kaliplar egitim verisinde iyi sonuclar almamizi saglerken test verisinde ayni performansi gostermezler. Buna, daha sonra detayli olarak gorecegimiz, *asiri uyum* adi verilir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "L4EqVWg4-llM"
      },
      "source": [
        "### Kayip fonksiyonu ve en iyilestirici\n",
        "\n",
        "Bir modelin egitimi icin kayip fonksiyonuna ve en iyilestiriciye ihtiyaci vardir. Bu ikili siniflandirma problemi oldugu icin ve modelin ciktisi olasilik (sigmoid aktiflestiricili tek-unite katmani) oldugu icin, biz `binary_crossentropy` kayip fonksiyonunu kullanacagiz.\n",
        "\n",
        "Bu kayip fonksiyonu icin tek secenegimiz degil, ornegin `mean_squared_error` fonksiyonunu da secebilirdik. Fakat, genellikle `binary_crossentropy` olasiliklar soz konusu oldugunda daha iyi sonuclar verir‚Äîolasilik dagilimlari arasindaki \"uzakliklari\" olcer, ya da bizim durumumuzda, tahminlerle gercek degerler arasindaki farki.\n",
        "\n",
        "Daha sonra, gerileme problemlerini incelerken (bir evin degerini tahmin ederken mesela), bir diger kayip fonksiyonu olan `mean squared error` fonksiyonunu kullanacagiz.\n",
        "\n",
        "Simdi modelimizi en iyilestirici ve kayip fonksiyonu kullanacak sekilde ayarlayalim:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Mr0GP-cQ-llN"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hCWYwkug-llQ"
      },
      "source": [
        "## Dogrulama setini olusturalim\n",
        "\n",
        "Modeli egitirken daha once gormedigi veride modelin dogrulugunu olcmek isteriz. Orjinal egitim verisinden 10,000 ornegi ayirarak *dogrulama setini* olusturun (Neden test setini simdi kullanmiyoruz? Amacimiz egitim verisini kullanarak modelimizi olusturmak ve ayarlamak, daha sonrasinda ise test verisini sadece bir kez kullanarak dogrulugunu degerlendirmek)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-NpcXY9--llS"
      },
      "outputs": [],
      "source": [
        "x_val = train_data[:10000]\n",
        "partial_x_train = train_data[10000:]\n",
        "\n",
        "y_val = train_labels[:10000]\n",
        "partial_y_train = train_labels[10000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "35jv_fzP-llU"
      },
      "source": [
        "## Modeli egitelim\n",
        "\n",
        "512 orneklik ufak obeklerle modelimizi 40 devirle egitelim. Bu `x_train` ve `y_train` tensorlarindaki butun ornekleri 40 kere yinelemek anlamina gelir. Egitim sirasinda modelin kaybini ve dogrulugunu dogrulama setindeki 10,000 ornekte takip edin:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tXSGrjWZ-llW"
      },
      "outputs": [],
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9EEGuDVuzb5r"
      },
      "source": [
        "## Modeli degerlendirelim\n",
        "\n",
        "Simdi modelimiz nasil calisiyor bir bakalim. Iki deger dondurulecek. Kayip (hatamizi temsil eden bir sayi, ne kadar dusuk o kadar iyi) ve dogruluk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zOMKywn4zReN"
      },
      "outputs": [],
      "source": [
        "results = model.evaluate(test_data, test_labels)\n",
        "\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z1iEXVTR0Z2t"
      },
      "source": [
        "Bu basit yontemle yaklasik %87 dogruluk degeri elde ettik. Daha gelismis yontemler kullanarak modelimizin %95 dogruluga ulasmasini saglayabiliriz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5KggXVeL-llZ"
      },
      "source": [
        "## Zaman icindeki dogruluk ve kayip degisimi grafigini olusturalim\n",
        "\n",
        "`model.fit()` fonksiyonu icinde egitim sirasinda olanlar sozlugunu barindiran `History` nesnesi dondurur:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "VcvSXvhp-llb"
      },
      "outputs": [],
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nRKsqL40-lle"
      },
      "source": [
        "Dort giris vardir: egitim ve dogrulama sirasinda takip edilen olcumleri hepsi icin bir tane. Bunlari kullanarak egitim ve dogrulama kayiplarini ve dogruluk degerlerini karsilastirmak icin cizebiliriz:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "nGoYf2Js-lle"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"bo\" \"mavi nokta\" anlamina gelir\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# b ise \"mavi cizgi\" yerine kullanilmistir\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "6hXx-xOv-llh"
      },
      "outputs": [],
      "source": [
        "plt.clf()   # Sekli temizle\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oFEmZ5zq-llk"
      },
      "source": [
        "\n",
        "Bu grafikte, noktalar egitim kaybini ve dogrulugunu temsil ederken, duz cizgiler dogrulama setinin kaybini ve dogrulugunu gosterir.\n",
        "\n",
        "Her devirde egitim kaybinin nasil *azaldigini* ve egitim dogrulugunun nasil *arttigini* gozlemleyelim. Bu meyil azalma en iyilestirmesi kullanilirken beklenen etkidir. Istenen miktar her yinelemede azami degere indirgenmelidir.\n",
        "\n",
        "Aynisi dogrulama setinin kaybiu ve dogruluk degeri icin soyleyemeyecegiz. Bu degerler yirmi devir sonrasinda zirveye ulasmis gibi gozukuyor. Bu asiri uyuma bir ornektir: model egitim verisinde hic gormedigi veriye gore daha iyi sonuclar verir. Bu noktadan sonra model fazladan en iyilestirme yapar ve egitim verisine *ozel* fakat test verisine *genellenemeyen* temsillemeleri ogrenir.\n",
        "\n",
        "Bu gordugumuz ornekte asiri uyumu yaklasik yirmi devir sonrasinda egitimi durdurarak onleyebiliriz. Daha sonra bunu otomatik olarak geri cagirma ile nasil yapacagimizi gorecegiz."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "text_classification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
