{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ic4_occAAiAT"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "ioaprt5q5US7"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "yCl0eTNH5RS3"
      },
      "outputs": [],
      "source": [
        "#@title MIT License\n",
        "#\n",
        "# Copyright (c) 2017 Fran√ßois Chollet\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ItXfxkxvosLH"
      },
      "source": [
        "# TensorFlow Hub ile Metin Siniflandirmasi: Film yorumlari"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hKY4XMc9o8iB"
      },
      "source": [
        "\u003ctable class=\"tfo-notebook-buttons\" align=\"left\"\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/keras/text_classification_with_hub\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" /\u003eView on TensorFlow.org\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification_with_hub.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /\u003eRun in Google Colab\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification_with_hub.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /\u003eView source on GitHub\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/keras/text_classification_with_hub.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/download_logo_32px.png\" /\u003eDownload notebook\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "\u003c/table\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Eg62Pmz3o83v"
      },
      "source": [
        "\n",
        "Bu kitapcikta film yorumlarini *olumlu* ve *olumsuz* olarak siniflandiracagiz. Bu makine ogrenmesinde cok kullanilan onemli bir problemin, *ikili* ya da iki-parcali-siniflandirmanin bir ornegidir.\n",
        "\n",
        "TensorFlow Hub ve Keras ile ogrenim aktarmasinin basit bir kullanimini bu egitimde gorecegiz.\n",
        "\n",
        "[Internet Movie Database](https://www.imdb.com/) sitesinden alinan 50,000 film yorumu metinini iceren [IMDB veri setini](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb) kullanacagiz. Bunlarin 25,000 adetini egitim icin ve geri kalan 25,000 adetini ise testler icin ayiralim. Egitim ve test setleri ayni sayida olumlu ve olumsuz yorumlar icerdikleri icin *dengelenmislerdir*. \n",
        "\n",
        "Bu kitapcik yuksek-seviye API olan [tf.keras](https://www.tensorflow.org/guide/keras) kullanarak modelleri TensorFlow ile olusturur ve egitir, ve ogrenim aktarmasi icin [TensorFlow Hub](https://www.tensorflow.org/hub) kitapligini ve platformunu kullanacagiz. `tf.keras` kullanan daha ileri bir metin siniflandirmasi egitim kitapcigi icin lutfen [MLCC Metin Siniflandirmasi Kilavuzua bakiniz](https://developers.google.com/machine-learning/guides/text-classification/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2ew7HTbPpCJH"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version sadece Colab icinde bulunur.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iAsKG535pHep"
      },
      "source": [
        "## IMDB veri setini indirelim\n",
        "\n",
        "IMDB veri setini [imdb yorumlari](https://github.com/tensorflow/datasets/blob/master/docs/datasets.md#imdb_reviews) ya da [TensorFlow veri setlerinde](https://github.com/tensorflow/datasets) bulabilirsiniz. Asagidaki kod IMDB veri setini makinenize (ya da colab calisma zamanina) indirir:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zXXx5Oc3pOmN"
      },
      "outputs": [],
      "source": [
        "# Egitim setini %60 ve %40 olarak ayiralim. Boylece 15,000 ornek egitim icin,\n",
        "# 10,000 ornek dogrulama icin ve 25,000 ornek ise test etmek icin kullanilabilir.\n",
        "train_validation_split = tfds.Split.TRAIN.subsplit([6, 4])\n",
        "\n",
        "(train_data, validation_data), test_data = tfds.load(\n",
        "    name=\"imdb_reviews\", \n",
        "    split=(train_validation_split, tfds.Split.TEST),\n",
        "    as_supervised=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l50X3GfjpU4r"
      },
      "source": [
        "## Veriyi inceleyelim \n",
        "\n",
        "Verinin yapisini anlamak icin bir goz atalim. Her ornek bir film yorumuna ait bir cumle ve etiketten olusur. Cumle herhangibir sekilde onceden islenmemistir. Etiket ise olumsuz yorumlar icin 0 veya olumlu yorumlar icin 1 olarak belirlenmistir.\n",
        "\n",
        "Ilk 10 ornegi ekrana yazdiralim."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QtTS4kpEpjbi"
      },
      "outputs": [],
      "source": [
        "train_examples_batch, train_labels_batch = next(iter(train_data.batch(10)))\n",
        "train_examples_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IFtaCHTdc-GY"
      },
      "source": [
        "Ilk 10 etiketi de yazdiralim."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tvAjVXOWc6Mj"
      },
      "outputs": [],
      "source": [
        "train_labels_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LLC02j2g-llC"
      },
      "source": [
        "## Modeli olusturalim\n",
        "\n",
        "Sinir agi katmanlarin ust uste konmasiyla olusturulur. Bu asamada uc ana mimari karar vermemiz gerekir:\n",
        "\n",
        "* Metini nasil temsil edecegiz?\n",
        "* Modelimizde kac katman kullanacagiz?\n",
        "* Her katman icin kac adet *sakli birim* kullanacagiz?\n",
        "\n",
        "Bu ornekte giris verisi cumlelerden olusur. Etiketler ise 0 ya da 1 idir.\n",
        "\n",
        "Metinleri temsil etmenin bir yolu cumleleri gomulu yoneylere cevirmektir. Onceden egitilmis metin gomulmesini ilk katmaninmiz olarak kullanabiliriz, ki bunun uc avantaji vardir:\n",
        "*   metin islenmesi icin kaygilanmamiza gerek kalmaz,\n",
        "*   ogrenim aktarimindan yararlanabiliriz,\n",
        "*   gomulmenin boyutu sabit oldugu icin islenmesi daha basittir.\n",
        "\n",
        "Bu ornekte [TensorFlow Hub](https://www.tensorflow.org/hub) icinde bulunan [google/tf2-preview/gnews-swivel-20dim/1](https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1) adindaki *onceden egitilmis bir metin gommesi modelini* kullanacagiz.\n",
        "\n",
        "Sectigimiz modele benzeyen uc adet daha onceden egitilmis model bulunmaktadir:\n",
        "\n",
        "* [google/tf2-preview/gnews-swivel-20dim-with-oov/1](https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim-with-oov/1) - [google/tf2-preview/gnews-swivel-20dim/1](https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1) ile ayni yapidadir, fakat sozlukteki kelimeler %2.5i, 00V kovalarina donusturulmustur. Eger modelinizin sozlugu ile kullanacaginiz metnin sozlugu birbiriyle ortusmezse bu donusum yardimci olabilir.\n",
        "* [google/tf2-preview/nnlm-en-dim50/1](https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1) - yaklasik 1 milyon kelimelik sozlugu ve 50 boyutu ile daha buyuk bir model.\n",
        "* [google/tf2-preview/nnlm-en-dim128/1](https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1) - yaklasik 1 milyon kelimelik sozlugu ve 128 boyutu ile daha da buyuk bir model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "In2nDpTLkgKa"
      },
      "source": [
        "Simdi TensorFlow Hub modeli ile cumlelerimizi gomecek bir Keras katmani olusturalim ve bunu birkac giris orneginde deneyelim. Giris metninin uzunluguna bagli olmadan, gomulme isleminden cikan butun verilerin su sekilde olduguna dikkat edelim: `(num_examples, embedding_dimension)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_NUbzVeYkgcO"
      },
      "outputs": [],
      "source": [
        "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
        "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
        "                           dtype=tf.string, trainable=True)\n",
        "hub_layer(train_examples_batch[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dfSbV6igl1EH"
      },
      "source": [
        "Simdi butun modeli olusturalim:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xpKOoWgu-llD"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(hub_layer)\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6PbKQ6mucuKL"
      },
      "source": [
        "Katmanlar sirayla ust uste konarak siniflandirici olusturulur:\n",
        "\n",
        "1. Ilk katman TensorFlow Hub katmani. Bu katman onceden egitilmis Saved Model kullanarak bir cumleyi gomulu yoneyiyle esler. Bizim burda kullandigimiz model, ([google/tf2-preview/gnews-swivel-20dim/1](https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1)), her cumleyi simgelere ayirir, bu simgeler gomer ve sonrasinda bu gommeleri bir araya getirir. Elde edilen sonuc su boyutlara sahiptir: `(num_examples, embedding_dimension)`.\n",
        "2. Bu sabit uzunluktaki cikis yoneyi 16 gizli birimli tamamen bagli (`Dense`) katmana gonderilir.\n",
        "3. Son katman ise tek cikis dugumlu yogun bagli bir katmandir. Sonucta olasiligi ya da guvenirlik seviyesini belirten, `sigmoid` etkinlestici fonksiyonu sonucu ortaya cika, 0 ile 1 arasinda bir reel sahi elde edilir.\n",
        "\n",
        "Modelimizi birlestirelim."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "L4EqVWg4-llM"
      },
      "source": [
        "### Kayip fonksiyonu ve en iyilestirici\n",
        "\n",
        "Bir modelin egitimi icin bir kayip fonksiyonu ve en iyilestirici gereklidir. Elimizde ikili siniflandirma problemi ve olasilik cikartan bir model bulundugu icin, `binary_crossentropy` kayip fonksiyonunu kullanacagiz. \n",
        "\n",
        "Bu kayip fonksiyonu icin tek secenegimiz degil, ornegin `mean_squared_error` fonksiyonunu da secebilirdik. Fakat olasilik hesaplari soz konusu oldugunda `binary_crossentropy` fonksiyonunun genellikle daha iyi oldugunu goruyoruz. Bu fonksiyon olasilik dagilimlari arasindaki \"uzakligi\" olcer, ki bu bizim ornegimizde gercek deger dagilimlari ile tahminler arasindaki uzakliktir.\n",
        "\n",
        "Daha sonra gerileme sorunlarini incelerken (bir evin degerini tahmin etme problemi gibi), bir baska kayip fonksiyonu olan 'mean squared error'u nasil kullanacagimizi gorecegiz.\n",
        "\n",
        "Simdi modelimizi kayip fonksiyonunu ve en iyilestiriciyi kullanacak sekilde ayarlayalim:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Mr0GP-cQ-llN"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "35jv_fzP-llU"
      },
      "source": [
        "## Modeli egitelim\n",
        "\n",
        "512 ornekten olusan kucuk topluluklarla modelimizi 20 devir suresince egitelim. Bu butun orneklerdeki `x_train` ve `y_train` tensorlarinda 20 kere yineleme anlamina gelir. Egitim sirasinda dogrulama setindeki 10,000 ornegi kullanarak modelimizin kaybini ve dogrulugunu takip edelim:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tXSGrjWZ-llW"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_data.shuffle(10000).batch(512),\n",
        "                    epochs=20,\n",
        "                    validation_data=validation_data.batch(512),\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9EEGuDVuzb5r"
      },
      "source": [
        "## Modeli degerlendirelim\n",
        "\n",
        "Modelimizin nasil calistigini inceleyelim. Iki degerin donduruldugunu goruyoruz. Kayip (hatamizi belirten bir sayi, ne kadar kucuk o kadar iyi) ve dogruluk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zOMKywn4zReN"
      },
      "outputs": [],
      "source": [
        "results = model.evaluate(test_data.batch(512), verbose=0)\n",
        "for name, value in zip(model.metrics_names, results):\n",
        "  print(\"%s: %.3f\" % (name, value))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z1iEXVTR0Z2t"
      },
      "source": [
        "Bu gorece basit yontemle yaklasik %87 degerinde bir dogruluk elde ettik. Daha ileri yontemlerle bu degeri %95'e cikartabiliriz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5KggXVeL-llZ"
      },
      "source": [
        "## Baska kaynaklar\n",
        "\n",
        "Dizgi girisleri ile calismak icin daha genel yontemler ve egitim sirasindaki dogruluk ile kaybin daha detayli analizleri icin [buraya goz atiniz](https://www.tensorflow.org/tutorials/keras/basic_text_classification)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "text_classification_with_hub.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
